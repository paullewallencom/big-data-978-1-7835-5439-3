{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SPARK TUTORIAL\n",
    " \n",
    " This tutorial has been reproduced with permission of Databricks Inc., a leading provider of Spark-based solutions.\n",
    " \n",
    "[Databricks](http://www.databricks.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 1A\n",
    "# This is a Python cell. You can run normal Python code here...\n",
    "print 'The sum of 1 and 1 is {0}'.format(1+1)\n",
    "\n",
    "# Here is another Python cell, this time with a variable (x) declaration and an if statement:\n",
    "x = 42\n",
    "if x > 40:\n",
    "    print 'The sum of 1 and 2 is {0}'.format(1+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 1B\n",
    "\n",
    "# This cell relies on x being defined already.\n",
    "# If we didn't run the cells from part (1a) this code would fail.\n",
    "print x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 1C\n",
    "\n",
    "# Import the regular expression library\n",
    "import re\n",
    "m = re.search('(?<=abc)def', 'abcdef')\n",
    "m.group(0)\n",
    "\n",
    "# Import the datetime library\n",
    "import datetime\n",
    "print 'This was last run on: {0}'.format(datetime.datetime.now())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 2A\n",
    "# Display the type of the Spark Context sc\n",
    "type(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 2B\n",
    "# List sc's attributes\n",
    "dir(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 2C\n",
    "\n",
    "# Use help to obtain more detailed information\n",
    "help(sc)\n",
    "\n",
    "# After reading the help we've decided we want to use sc.version to see what version of Spark we are running\n",
    "sc.version\n",
    "\n",
    "# Help can be used on any Python object\n",
    "help(map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3A\n",
    "data = xrange(1, 10001)\n",
    "\n",
    "# Data is just a normal Python list\n",
    "# Obtain data's first element\n",
    "data[0]\n",
    "\n",
    "# We can check the size of the list using the len() function\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3B\n",
    "# Parallelize data using 8 partitions\n",
    "# This operation is a transformation of data into an RDD\n",
    "# Spark uses lazy evaluation, so no Spark jobs are run at this point\n",
    "xrangeRDD = sc.parallelize(data, 8)\n",
    "\n",
    "# Let's view help on parallelize\n",
    "help(sc.parallelize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3B Continued\n",
    "# Let's see what type sc.parallelize() returned\n",
    "print 'type of xrangeRDD: {0}'.format(type(xrangeRDD))\n",
    "\n",
    "# How about if we use a range\n",
    "dataRange = range(1, 10001)\n",
    "rangeRDD = sc.parallelize(dataRange, 8)\n",
    "print 'type of dataRangeRDD: {0}'.format(type(rangeRDD))\n",
    "\n",
    "# Each RDD gets a unique ID\n",
    "print 'xrangeRDD id: {0}'.format(xrangeRDD.id())\n",
    "print 'rangeRDD id: {0}'.format(rangeRDD.id())\n",
    "\n",
    "# We can name each newly created RDD using the setName() method\n",
    "xrangeRDD.setName('My first RDD')\n",
    "\n",
    "# Let's view the lineage (the set of transformations) of the RDD using toDebugString()\n",
    "print xrangeRDD.toDebugString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3B Continued\n",
    "# Let's use help to see what methods we can call on this RDD\n",
    "help(xrangeRDD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3B Continued\n",
    "\n",
    "# Let's see how many partitions the RDD will be split into by using the getNumPartitions()\n",
    "xrangeRDD.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3C\n",
    "# Create sub function to subtract 1\n",
    "def sub(value):\n",
    "    \"\"\"\"Subtracts one from `value`.\n",
    "\n",
    "    Args:\n",
    "       value (int): A number.\n",
    "\n",
    "    Returns:\n",
    "        int: `value` minus one.\n",
    "    \"\"\"\n",
    "    return (value - 1)\n",
    "\n",
    "# Transform xrangeRDD through map transformation using sub function\n",
    "# Because map is a transformation and Spark uses lazy evaluation, no jobs, stages,\n",
    "# or tasks will be launched when we run this code.\n",
    "subRDD = xrangeRDD.map(sub)\n",
    "\n",
    "# Let's see the RDD transformation hierarchy\n",
    "print subRDD.toDebugString()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3D\n",
    "# Let's collect the data\n",
    "print subRDD.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3D Continued\n",
    "print xrangeRDD.count()\n",
    "print subRDD.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 3E\n",
    "# Define a function to filter a single value\n",
    "def ten(value):\n",
    "    \"\"\"Return whether value is below ten.\n",
    "\n",
    "    Args:\n",
    "        value (int): A number.\n",
    "\n",
    "    Returns:\n",
    "        bool: Whether `value` is less than ten.\n",
    "    \"\"\"\n",
    "    if (value < 10):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# The ten function could also be written concisely as: def ten(value): return value < 10\n",
    "\n",
    "# Pass the function ten to the filter transformation\n",
    "# Filter is a transformation so no tasks are run\n",
    "filteredRDD = subRDD.filter(ten)\n",
    "\n",
    "# View the results using collect()\n",
    "# Collect is an action and triggers the filter transformation to run\n",
    "print filteredRDD.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 4\n",
    "\n",
    "lambdaRDD = subRDD.filter(lambda x: x < 10)\n",
    "lambdaRDD.collect()\n",
    "\n",
    "# Let's collect the even values less than 10\n",
    "evenRDD = lambdaRDD.filter(lambda x: x % 2 == 0)\n",
    "evenRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 5A\n",
    "\n",
    "# Let's get the first element\n",
    "print filteredRDD.first()\n",
    "# The first 4\n",
    "print filteredRDD.take(4)\n",
    "# Note that it is ok to take more elements than the RDD has\n",
    "print filteredRDD.take(12)\n",
    "\n",
    "# Retrieve the three smallest elements\n",
    "print filteredRDD.takeOrdered(3)\n",
    "# Retrieve the five largest elements\n",
    "print filteredRDD.top(5)\n",
    "\n",
    "# Pass a lambda function to takeOrdered to reverse the order\n",
    "filteredRDD.takeOrdered(4, lambda s: -s)\n",
    "\n",
    "# Obtain Python's add function\n",
    "from operator import add\n",
    "# Efficiently sum the RDD using reduce\n",
    "print filteredRDD.reduce(add)\n",
    "# Sum using reduce with a lambda function\n",
    "print filteredRDD.reduce(lambda a, b: a + b)\n",
    "# Note that subtraction is not both associative and commutative\n",
    "print filteredRDD.reduce(lambda a, b: a - b)\n",
    "print filteredRDD.repartition(4).reduce(lambda a, b: a - b)\n",
    "# While addition is\n",
    "print filteredRDD.repartition(4).reduce(lambda a, b: a + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 5B\n",
    "# takeSample reusing elements\n",
    "print filteredRDD.takeSample(withReplacement=True, num=6)\n",
    "# takeSample without reuse\n",
    "print filteredRDD.takeSample(withReplacement=False, num=6)\n",
    "\n",
    "# Set seed for predictability\n",
    "print filteredRDD.takeSample(withReplacement=False, num=6, seed=500)\n",
    "# Try reruning this cell and the cell above -- the results from this cell will remain constant\n",
    "# Use ctrl-enter to run without moving to the next cell\n",
    "\n",
    "# Create new base RDD to show countByValue\n",
    "repetitiveRDD = sc.parallelize([1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 3, 3, 4, 5, 4, 6])\n",
    "print repetitiveRDD.countByValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 6A\n",
    "\n",
    "# Let's create a new base RDD to work from\n",
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "\n",
    "# Use map\n",
    "singularAndPluralWordsRDDMap = wordsRDD.map(lambda x: (x, x + 's'))\n",
    "# Use flatMap\n",
    "singularAndPluralWordsRDD = wordsRDD.flatMap(lambda x: (x, x + 's'))\n",
    "\n",
    "# View the results\n",
    "print singularAndPluralWordsRDDMap.collect()\n",
    "print singularAndPluralWordsRDD.collect()\n",
    "# View the number of elements in the RDD\n",
    "print singularAndPluralWordsRDDMap.count()\n",
    "print singularAndPluralWordsRDD.count()\n",
    "\n",
    "simpleRDD = sc.parallelize([2, 3, 4])\n",
    "print simpleRDD.map(lambda x: range(1, x)).collect()\n",
    "print simpleRDD.flatMap(lambda x: range(1, x)).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 6B\n",
    "\n",
    "pairRDD = sc.parallelize([('a', 1), ('a', 2), ('b', 1)])\n",
    "# mapValues only used to improve format for printing\n",
    "print pairRDD.groupByKey().mapValues(lambda x: list(x)).collect()\n",
    "\n",
    "# Different ways to sum by key\n",
    "print pairRDD.groupByKey().map(lambda (k, v): (k, sum(v))).collect()\n",
    "# Using mapValues, which is recommended when they key doesn't change\n",
    "print pairRDD.groupByKey().mapValues(lambda x: sum(x)).collect()\n",
    "# reduceByKey is more efficient / scalable\n",
    "print pairRDD.reduceByKey(add).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 6C\n",
    "\n",
    "# mapPartitions takes a function that takes an iterator and returns an iterator\n",
    "print wordsRDD.collect()\n",
    "itemsRDD = wordsRDD.mapPartitions(lambda iterator: [','.join(iterator)])\n",
    "print itemsRDD.collect()\n",
    "\n",
    "itemsByPartRDD = wordsRDD.mapPartitionsWithIndex(lambda index, iterator: [(index, list(iterator))])\n",
    "# We can see that three of the (partitions) workers have one element and the fourth worker has two\n",
    "# elements, although things may not bode well for the rat...\n",
    "print itemsByPartRDD.collect()\n",
    "# Rerun without returning a list (acts more like flatMap)\n",
    "itemsByPartRDD = wordsRDD.mapPartitionsWithIndex(lambda index, iterator: (index, list(iterator)))\n",
    "print itemsByPartRDD.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 7A\n",
    "# Name the RDD\n",
    "filteredRDD.setName('My Filtered RDD')\n",
    "# Cache the RDD\n",
    "filteredRDD.cache()\n",
    "# Is it cached\n",
    "print filteredRDD.is_cached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 7B\n",
    "# Note that toDebugString also provides storage information\n",
    "print filteredRDD.toDebugString()\n",
    "\n",
    "# If we are done with the RDD we can unpersist it so that its memory can be reclaimed\n",
    "filteredRDD.unpersist()\n",
    "# Storage level for a non cached RDD\n",
    "print filteredRDD.getStorageLevel()\n",
    "filteredRDD.cache()\n",
    "# Storage level for a cached RDD\n",
    "print filteredRDD.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 8A\n",
    "\n",
    "def brokenTen(value):\n",
    "    \"\"\"Incorrect implementation of the ten function.\n",
    "\n",
    "    Note:\n",
    "        The `if` statement checks an undefined variable `val` instead of `value`.\n",
    "\n",
    "    Args:\n",
    "        value (int): A number.\n",
    "\n",
    "    Returns:\n",
    "        bool: Whether `value` is less than ten.\n",
    "\n",
    "    Raises:\n",
    "        NameError: The function references `val`, which is not available in the local or global\n",
    "            namespace, so a `NameError` is raised.\n",
    "    \"\"\"\n",
    "    if (value < 10):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "brokenRDD = subRDD.filter(brokenTen)\n",
    "\n",
    "# Now we'll see the error\n",
    "brokenRDD.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 8C\n",
    "# Cleaner code through lambda use\n",
    "subRDD.filter(lambda x: x < 10).collect()\n",
    "\n",
    "# Even better by moving our chain of operators into a single line.\n",
    "sc.parallelize(data).map(lambda y: y - 1).filter(lambda x: x < 10).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Section 8D\n",
    "(sc\n",
    " .parallelize(data)\n",
    " .map(lambda y: y - 1)\n",
    " .filter(lambda x: x < 10)\n",
    " .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "Packt_Notebook",
  "notebookId": 2573898132801625
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
